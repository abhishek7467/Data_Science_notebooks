{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek7467/Data_Science_notebooks/blob/main/my_SAM_HQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-f6BIbf6OtM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import torch\n",
        "from PIL import Image\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "\n",
        "# !git clone https://github.com/SysCV/sam-hq.git\n",
        "# !pip install timm\n",
        "os.chdir('sam-hq')\n",
        "# !export PYTHONPATH=$(pwd)\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiK433NK6OtO"
      },
      "outputs": [],
      "source": [
        "# !mkdir pretrained_checkpoint\n",
        "# !wget https://huggingface.co/lkeab/hq-sam/resolve/main/sam_hq_vit_l.pth\n",
        "# !mv sam_hq_vit_l.pth pretrained_checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl1XJVDn6OtO"
      },
      "outputs": [],
      "source": [
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
        "        img[m] = color_mask\n",
        "    ax.imshow(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvr0NGGL6OtO"
      },
      "outputs": [],
      "source": [
        "img_path =r\"C:\\Users\\spx016\\Downloads\\Images_With_output_RMBG\\image_20241211_193112.jpeg\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwFPCc9i6OtO"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(img_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qYfTZ0l6OtO"
      },
      "outputs": [],
      "source": [
        "sam_checkpoint = \"E:\\Image_Segmentation\\sam-hq\\pretrained_checkpoint\\sam_hq_vit_h.pth\"\n",
        "model_type = \"vit_h\"\n",
        "device = \"cuda\"\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "sam.eval()\n",
        "predictor = SamPredictor(sam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXoFa2fn6OtP"
      },
      "outputs": [],
      "source": [
        "image = Image.open(img_path)\n",
        "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "target_sizes = torch.tensor([image.size[::-1]])\n",
        "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lapGRIBV6OtP"
      },
      "outputs": [],
      "source": [
        "id2label = {1: \"motorcycle\"}\n",
        "img  = np.array(image)\n",
        "img_real = np.array(image)\n",
        "img_2 = np.array(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUKpCLOp6OtP"
      },
      "outputs": [],
      "source": [
        "predictor.set_image(img_real)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSWdiTJK6OtP"
      },
      "outputs": [],
      "source": [
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    print(\"box \", type(box), box , \"score\" ,score.item())\n",
        "    box = box.detach().cpu().numpy()\n",
        "    box = [int(round(i)) for i in box]\n",
        "    x1, y1, x2, y2 = box\n",
        "    label_name = id2label.get(label.item(), \"Unknown\")\n",
        "    confidence = score.item()\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    text = f\"{label_name} ({confidence})\"\n",
        "    text_y = max(y1 - 10, 10)\n",
        "    cv2.putText(img, text, (x1, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "file_path = \"E:\\Image_Segmentation\\sam-hq\\myImage.png\"\n",
        "print(cv2.imwrite(file_path, img))\n",
        "{os.path.abspath(file_path)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIfKaKQI6OtP"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSJNVX_I6OtQ"
      },
      "outputs": [],
      "source": [
        "results[\"scores\"].detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzOgrTzA6OtQ"
      },
      "outputs": [],
      "source": [
        "print(np.argmax(results[\"scores\"].detach().cpu().numpy()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL5jj0kV6OtQ"
      },
      "outputs": [],
      "source": [
        "id2label = {1: \"motorcycle\"}\n",
        "img_2 = np.array(image)\n",
        "box1 = results[\"boxes\"][np.argmax(results[\"scores\"].detach().cpu().numpy())].detach().cpu().numpy()\n",
        "box1 = [int(round(i)) for i in box1]\n",
        "x1, y1, x2, y2 = box1\n",
        "label_name = id2label.get(label.item(), \"Unknown\")\n",
        "confidence = score.item()\n",
        "cv2.rectangle(img_2, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "text = f\"{label_name} ({confidence})\"\n",
        "text_y = max(y1 - 10, 10)\n",
        "cv2.putText(img_2, text, (x1, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EItekY46OtQ"
      },
      "outputs": [],
      "source": [
        "input_box = np.array(box1)\n",
        "input_label = np.array([1])\n",
        "input_point = np.array([[(x1 + x2) / 2, (y1 + y2) / 2]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oS8qJdM6OtQ"
      },
      "outputs": [],
      "source": [
        "masks, scores, logits = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        box = input_box,\n",
        "        multimask_output=False,\n",
        "        hq_token_only=True,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON00zUju6OtQ"
      },
      "outputs": [],
      "source": [
        "mask_uint8 = masks.astype(np.uint8) * 255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvEjP8sD6OtQ"
      },
      "outputs": [],
      "source": [
        "mask_color = cv2.merge([mask_uint8, np.zeros_like(mask_uint8), np.zeros_like(mask_uint8)])\n",
        "mask_color = np.squeeze(mask_color)\n",
        "plt.imshow(mask_color)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txx_3qzP6OtQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Extract the red channel from `mask_color` to create a binary mask\n",
        "binary_mask = mask_color[..., 0]  # Use only the red channel as `mask_color` is created with red\n",
        "\n",
        "# Ensure the mask is binary (values: 0 or 255)\n",
        "binary_mask = (binary_mask > 0).astype(np.uint8) * 255\n",
        "\n",
        "# Step 2: Resize the mask to match the image size, if needed\n",
        "if binary_mask.shape[:2] != img_real.shape[:2]:\n",
        "    binary_mask = cv2.resize(binary_mask, (img_real.shape[1], img_real.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "# Step 3: Extract the object using bitwise operation\n",
        "object_extracted = cv2.bitwise_and(img_real, img_real, mask=binary_mask)\n",
        "\n",
        "# Step 4: Create a transparent background (optional, if you want PNG with transparency)\n",
        "object_with_alpha = np.zeros((img_real.shape[0], img_real.shape[1], 4), dtype=np.uint8)\n",
        "object_with_alpha[..., :3] = object_extracted  # Copy RGB channels\n",
        "object_with_alpha[..., 3] = binary_mask        # Add alpha channel based on the mask\n",
        "# Step 5: Display the result\n",
        "plt.figure(figsize=(8, 8))\n",
        "cv2.imwrite(\"C:\\\\Users\\\\spx016\\\\Downloads\\\\image (2) (1).png\", object_with_alpha)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(object_extracted, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Extracted Object\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5ovd97b6OtQ"
      },
      "outputs": [],
      "source": [
        "# if len(mask_uint8.shape) == 3:\n",
        "#     mask_uint8 = mask_uint8[..., 0]\n",
        "# if mask_uint8.shape[:2] != img_real.shape[:2]:\n",
        "#     mask = cv2.resize(mask_uint8, (img_real.shape[1], img_real.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "# else:\n",
        "#     mask = mask_uint8\n",
        "# transparent_object = np.zeros((img_real.shape[0], img_real.shape[1], 4), dtype=np.uint8)\n",
        "# transparent_object[..., :3] = img_real\n",
        "# transparent_object[..., 3] = mask\n",
        "# cv2.imwrite(\"C:\\\\Users\\\\spx016\\\\Downloads\\\\image (2) (1).png\", transparent_object)\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# plt.imshow(cv2.cvtColor(transparent_object[..., :3], cv2.COLOR_BGR2RGB))\n",
        "# plt.axis(\"off\")\n",
        "# plt.title(\"Extracted Object with Transparency\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXQkGecD6OtQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "image_dir = \"C:\\\\Users\\\\spx016\\\\Downloads\\\\Images_With_output_RMBG\\\\\"\n",
        "output_image_dir = \"C:\\\\Users\\\\spx016\\\\Downloads\\\\Image_With_Output_SAM_resnet50\\\\\"\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.bmp', '.gif', '.webp')):\n",
        "        # Full path to the image file\n",
        "        filepath = os.path.join(image_dir, filename)\n",
        "\n",
        "        image = Image.open(filepath)\n",
        "        processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "        model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "        inputs = processor(images=image, return_tensors=\"pt\")\n",
        "        outputs = model(**inputs)\n",
        "        target_sizes = torch.tensor([image.size[::-1]])\n",
        "        results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
        "        img_real = np.array(image)\n",
        "        predictor.set_image(img_real)\n",
        "\n",
        "        id2label = {1: \"motorcycle\"}\n",
        "        img_2 = np.array(image)\n",
        "        try:\n",
        "            box1 = results[\"boxes\"][np.argmax(results[\"scores\"].detach().cpu().numpy())].detach().cpu().numpy()\n",
        "            box1 = [int(round(i)) for i in box1]\n",
        "            input_box = np.array(box1)\n",
        "            input_label = np.array([1])\n",
        "            input_point = np.array([[(x1 + x2) / 2, (y1 + y2) / 2]])\n",
        "\n",
        "\n",
        "            masks, scores, logits = predictor.predict(\n",
        "            point_coords=input_point,\n",
        "            point_labels=input_label,\n",
        "            box = input_box,\n",
        "            multimask_output=False,\n",
        "            hq_token_only=True,\n",
        "            )\n",
        "\n",
        "            mask_uint8 = masks.astype(np.uint8) * 255\n",
        "\n",
        "            mask_color = cv2.merge([mask_uint8, np.zeros_like(mask_uint8), np.zeros_like(mask_uint8)])\n",
        "            mask_color = np.squeeze(mask_color)\n",
        "\n",
        "            # Step 1: Extract the red channel from `mask_color` to create a binary mask\n",
        "            binary_mask = mask_color[..., 0]  # Use only the red channel as `mask_color` is created with red\n",
        "\n",
        "            # Ensure the mask is binary (values: 0 or 255)\n",
        "            binary_mask = (binary_mask > 0).astype(np.uint8) * 255\n",
        "\n",
        "            # Step 2: Resize the mask to match the image size, if needed\n",
        "            if binary_mask.shape[:2] != img_real.shape[:2]:\n",
        "                binary_mask = cv2.resize(binary_mask, (img_real.shape[1], img_real.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            # Step 3: Extract the object using bitwise operation\n",
        "            object_extracted = cv2.bitwise_and(img_real, img_real, mask=binary_mask)\n",
        "\n",
        "            # Step 4: Create a transparent background (optional, if you want PNG with transparency)\n",
        "            object_with_alpha = np.zeros((img_real.shape[0], img_real.shape[1], 4), dtype=np.uint8)\n",
        "            object_with_alpha[..., :3] = object_extracted  # Copy RGB channels\n",
        "            object_with_alpha[..., 3] = binary_mask        # Add alpha channel based on the mask\n",
        "            # Step 5: Display the result\n",
        "            base_name, ext = os.path.splitext(filename)\n",
        "\n",
        "            # Create the output file name with the original name and \"__removedObj\" appended\n",
        "            output_filename = f\"{base_name}__removedObj.png\"\n",
        "            output_path = os.path.join(output_image_dir, output_filename)\n",
        "\n",
        "            cv2.imwrite(output_path, object_with_alpha)\n",
        "            # Save the image\n",
        "\n",
        "            INput_filename = f\"{base_name}____{ext}\"\n",
        "            INput_path = os.path.join(output_image_dir, INput_filename)\n",
        "            image.save(INput_path)\n",
        "            print(f\"Saved image: {output_path}\")\n",
        "            print(f\"Saved image: {INput_path}\")\n",
        "        except:\n",
        "            print(\"  Except Saved image \")\n",
        "            INput_filename = f\"{base_name}__non_SEGMENTATION__{ext}\"\n",
        "            INput_path = os.path.join(output_image_dir, INput_filename)\n",
        "            image.save(INput_path)\n",
        "            print(f\"Except Saved image: {INput_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-t7xP3F6OtR"
      },
      "outputs": [],
      "source": [
        "# Except Saved image: C:\\Users\\spx016\\Downloads\\Image_With_Output_SAM_resnet50\\image_20241211_192652__non_SEGMENTATION__.jpg\n",
        "# Except Saved image: C:\\Users\\spx016\\Downloads\\Image_With_Output_SAM_resnet50\\image_20241211_193112__non_SEGMENTATION__.jpeg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYTVpT5I6OtR"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
        "import cv2 , torch\n",
        "processor = AutoImageProcessor.from_pretrained(\"ArrayDice/Vehicle_Detection_Model_Zoom\")\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"ArrayDice/Vehicle_Detection_Model_Zoom\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EamzbTFW6OtR"
      },
      "outputs": [],
      "source": [
        "img_path =r\"C:\\Users\\spx016\\Downloads\\object-detection_bike\\image_20241211_193116____.jpg\"\n",
        "image = cv2.imread(img_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrZCxpQ06OtR"
      },
      "outputs": [],
      "source": [
        "# Load model and processor\n",
        "processor = AutoImageProcessor.from_pretrained(\"ArrayDice/Vehicle_Detection_Model_Zoom\")\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"ArrayDice/Vehicle_Detection_Model_Zoom\")\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_path = r\"C:\\Users\\spx016\\Downloads\\object-detection_bike\\image_20241211_193116____.jpg\"\n",
        "image = cv2.imread(img_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = image / 255.0\n",
        "\n",
        "# Process the image with the model\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "output = model(**inputs)\n",
        "\n",
        "# Correctly define target_sizes from image.shape\n",
        "height, width, _ = image.shape  # Get height and width of the image\n",
        "target_sizes = torch.tensor([[height, width]])  # Use the correct format for target_sizes\n",
        "\n",
        "# Post-process the model outputs\n",
        "results = processor.post_process_object_detection(output, target_sizes=target_sizes, threshold=0.9)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiSBaBDk6OtR",
        "outputId": "7975c0b8-6719-4210-a1d1-c2ef5685c679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.9972, 0.9986, 0.9980, 0.9978, 0.9985, 0.9989, 0.9987, 0.9988, 0.9976,\n",
            "        0.9948, 0.9979, 0.9975, 0.9982, 0.9980, 0.9983, 0.9980, 0.9945, 0.9983,\n",
            "        0.9985, 0.9984, 0.9979, 0.9979, 0.9968, 0.9972, 0.9990, 0.9989, 0.9979,\n",
            "        0.9989, 0.9982, 0.9970, 0.9969, 0.9985, 0.9977, 0.9980, 0.9979, 0.9987,\n",
            "        0.9981, 0.9989, 0.9988, 0.9988, 0.9985, 0.9974, 0.9986, 0.9979, 0.9979,\n",
            "        0.9990, 0.9989, 0.9985, 0.9971, 0.9989, 0.9968, 0.9987, 0.9979, 0.9988,\n",
            "        0.9987, 0.9988, 0.9981, 0.9987, 0.9986, 0.9979, 0.9986, 0.9988, 0.9958,\n",
            "        0.9984, 0.9956, 0.9984, 0.9959, 0.9980, 0.9987, 0.9977, 0.9978, 0.9988,\n",
            "        0.9988, 0.9989, 0.9975, 0.9990, 0.9988, 0.9969, 0.9987, 0.9973, 0.9975,\n",
            "        0.9988, 0.9967, 0.9967, 0.9989, 0.9978, 0.9973, 0.9989, 0.9978, 0.9988,\n",
            "        0.9989, 0.9985, 0.9980, 0.9987, 0.9989, 0.9984, 0.9985, 0.9978, 0.9985,\n",
            "        0.9987], grad_fn=<IndexBackward0>)\n",
            "tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
            "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11])\n",
            "tensor([[4.5380e+00, 4.6052e+02, 9.1630e+00, 8.6789e+01],\n",
            "        [5.9445e+02, 5.6367e+01, 1.7847e+02, 3.6216e+01],\n",
            "        [4.3400e+01, 6.1541e+02, 8.6965e+01, 7.6734e+01],\n",
            "        [8.1051e+02, 1.3669e+00, 1.7504e+02, 2.8274e+00],\n",
            "        [4.0748e+02, 7.4645e+00, 1.7305e+02, 1.4907e+01],\n",
            "        [2.8385e+02, 4.5977e+02, 1.5859e+02, 6.8091e+01],\n",
            "        [4.8688e+02, 3.7353e+02, 2.1122e+02, 8.4452e+01],\n",
            "        [1.3506e+02, 4.9597e+02, 1.3392e+02, 6.7962e+01],\n",
            "        [1.1514e+02, 2.8315e+00, 1.4522e+02, 5.8868e+00],\n",
            "        [4.6816e+01, 1.8812e+00, 8.9438e+01, 3.9274e+00],\n",
            "        [1.1849e+03, 6.2958e+02, 3.0445e+01, 6.9944e+01],\n",
            "        [1.0155e+01, 5.5165e+02, 2.0556e+01, 8.9206e+01],\n",
            "        [1.1900e+03, 3.8901e+02, 2.0092e+01, 1.3456e+02],\n",
            "        [1.1800e+03, 5.3827e+02, 4.0048e+01, 7.7460e+01],\n",
            "        [5.2512e+02, 7.1185e+02, 2.0887e+02, 2.1571e+01],\n",
            "        [1.7406e+01, 4.5703e+01, 3.5774e+01, 5.0850e+01],\n",
            "        [4.4228e+01, 4.0343e+00, 8.6549e+01, 8.2994e+00],\n",
            "        [1.1292e+03, 9.4948e+00, 1.2123e+02, 1.9768e+01],\n",
            "        [1.1868e+03, 3.6944e+02, 2.6820e+01, 8.7172e+01],\n",
            "        [6.1840e+01, 6.9604e+01, 1.1413e+02, 5.1179e+01],\n",
            "        [1.1846e+03, 5.4856e+02, 3.0730e+01, 8.5757e+01],\n",
            "        [1.1924e+03, 4.9130e+02, 1.5243e+01, 8.4486e+01],\n",
            "        [1.1942e+03, 4.3416e+01, 1.1565e+01, 6.1029e+01],\n",
            "        [1.1941e+03, 5.8605e+02, 1.1793e+01, 8.6054e+01],\n",
            "        [1.0356e+03, 1.6782e+02, 1.4177e+02, 6.0520e+01],\n",
            "        [1.1440e+03, 4.9317e+02, 9.9019e+01, 6.6475e+01],\n",
            "        [1.1912e+03, 1.3746e+02, 1.7724e+01, 1.0681e+02],\n",
            "        [1.4116e+02, 4.9722e+02, 1.3836e+02, 6.7416e+01],\n",
            "        [5.6309e+02, 3.6380e+00, 1.7520e+02, 7.5301e+00],\n",
            "        [4.0372e+00, 5.6825e+01, 8.2538e+00, 6.9379e+01],\n",
            "        [2.5031e+00, 5.6411e+02, 5.0650e+00, 8.7936e+01],\n",
            "        [2.7139e+02, 6.7883e+02, 1.6135e+02, 4.9363e+01],\n",
            "        [3.9400e+01, 6.7076e+02, 8.0113e+01, 7.0938e+01],\n",
            "        [1.1906e+03, 3.5542e+02, 1.8562e+01, 9.0108e+01],\n",
            "        [1.1949e+03, 3.3647e+02, 1.0266e+01, 1.6232e+02],\n",
            "        [4.1838e+02, 1.8561e+02, 1.7469e+02, 6.5048e+01],\n",
            "        [1.1875e+03, 4.0868e+02, 2.5084e+01, 1.0435e+02],\n",
            "        [1.1852e+02, 2.8303e+02, 1.3290e+02, 8.7205e+01],\n",
            "        [1.9442e+02, 5.4671e+02, 1.6389e+02, 5.8999e+01],\n",
            "        [1.0146e+03, 8.7646e+01, 1.5117e+02, 4.7231e+01],\n",
            "        [1.1774e+03, 7.5932e+01, 4.5893e+01, 6.1592e+01],\n",
            "        [1.1726e+03, 7.1687e+00, 5.4890e+01, 1.4667e+01],\n",
            "        [6.6633e+02, 1.4270e+01, 1.9561e+02, 2.0029e+01],\n",
            "        [2.5711e+01, 6.0820e+02, 5.1763e+01, 6.9928e+01],\n",
            "        [8.8021e+00, 2.3898e+02, 1.7918e+01, 9.3234e+01],\n",
            "        [2.4139e+02, 1.8782e+02, 1.5934e+02, 5.7740e+01],\n",
            "        [1.1110e+03, 1.6972e+02, 1.2233e+02, 6.4018e+01],\n",
            "        [9.3155e+02, 6.9674e+02, 1.6874e+02, 3.6686e+01],\n",
            "        [7.4110e+00, 1.3272e+02, 1.5458e+01, 2.5996e+02],\n",
            "        [2.0748e+02, 3.4927e+02, 1.6595e+02, 8.2610e+01],\n",
            "        [4.0509e+02, 1.0196e+00, 1.6717e+02, 2.1029e+00],\n",
            "        [1.1180e+03, 1.9679e+01, 1.2313e+02, 2.5749e+01],\n",
            "        [9.7301e+01, 7.0050e+02, 1.6105e+02, 4.0854e+01],\n",
            "        [2.7256e+02, 2.1108e+02, 1.5718e+02, 6.5381e+01],\n",
            "        [5.2159e+01, 5.6579e+02, 8.7136e+01, 7.3488e+01],\n",
            "        [3.1057e+01, 5.2479e+02, 6.1388e+01, 7.8426e+01],\n",
            "        [1.3553e+01, 4.6006e+02, 2.7280e+01, 7.7431e+01],\n",
            "        [6.3216e+02, 2.3847e+02, 2.1206e+02, 7.4419e+01],\n",
            "        [4.8043e+02, 1.0747e+02, 2.0802e+02, 5.8388e+01],\n",
            "        [5.9972e+02, 9.3959e+00, 7.4477e+02, 2.1938e+01],\n",
            "        [2.1930e+02, 1.6525e+01, 1.8537e+02, 2.6855e+01],\n",
            "        [2.4025e+01, 4.5210e+02, 5.2692e+01, 8.3769e+01],\n",
            "        [1.1905e+03, 9.4774e+00, 1.8878e+01, 1.9149e+01],\n",
            "        [8.0562e+01, 3.1126e+01, 1.1596e+02, 3.5435e+01],\n",
            "        [1.1203e+03, 1.5479e+00, 1.4001e+02, 3.1645e+00],\n",
            "        [1.0022e+02, 6.6309e+02, 1.4581e+02, 6.8678e+01],\n",
            "        [7.9276e+00, 8.1954e+00, 1.6033e+01, 1.6983e+01],\n",
            "        [1.5158e+01, 4.9677e+02, 3.0860e+01, 1.1525e+02],\n",
            "        [1.6672e+02, 2.0472e+02, 1.5172e+02, 6.7569e+01],\n",
            "        [1.1959e+03, 3.2429e+02, 8.0482e+00, 1.1475e+02],\n",
            "        [1.1752e+03, 2.0182e+01, 4.9704e+01, 3.6256e+01],\n",
            "        [5.4328e+02, 4.3028e+01, 3.3700e+02, 5.1400e+01],\n",
            "        [6.1743e+02, 6.5855e+01, 6.2650e+02, 9.4268e+01],\n",
            "        [1.1199e+03, 4.3709e+02, 1.1570e+02, 7.0571e+01],\n",
            "        [1.1790e+03, 6.6881e+02, 4.1850e+01, 7.2623e+01],\n",
            "        [1.1459e+03, 2.3360e+02, 9.8608e+01, 7.3693e+01],\n",
            "        [1.9020e+01, 4.0810e+02, 3.9635e+01, 9.5806e+01],\n",
            "        [6.1315e+00, 6.2162e+02, 1.2395e+01, 9.0384e+01],\n",
            "        [2.9402e+02, 3.9150e+01, 1.6718e+02, 2.8270e+01],\n",
            "        [1.2147e+01, 2.4817e+01, 2.4925e+01, 4.4048e+01],\n",
            "        [1.1922e+03, 5.3492e+02, 1.5655e+01, 9.2633e+01],\n",
            "        [3.3535e+02, 3.8818e+02, 1.8105e+02, 8.1274e+01],\n",
            "        [1.1964e+03, 5.1987e+02, 7.0327e+00, 9.9167e+01],\n",
            "        [6.0093e+02, 8.2529e-01, 1.8045e+02, 1.7148e+00],\n",
            "        [9.7717e+01, 3.2120e+02, 1.1650e+02, 8.5727e+01],\n",
            "        [1.1840e+03, 6.2257e+02, 3.1856e+01, 7.5705e+01],\n",
            "        [1.1949e+03, 4.8838e+02, 1.0126e+01, 8.5624e+01],\n",
            "        [9.9952e+02, 7.7094e+01, 1.6195e+02, 4.7110e+01],\n",
            "        [2.3561e+01, 6.1286e+02, 4.7539e+01, 7.6049e+01],\n",
            "        [6.2224e+02, 5.1097e+02, 1.8932e+02, 6.7629e+01],\n",
            "        [9.2029e+02, 3.2488e+02, 1.8485e+02, 9.1749e+01],\n",
            "        [1.1860e+03, 1.5555e+02, 2.8688e+01, 9.5786e+01],\n",
            "        [1.1908e+03, 4.8914e+02, 1.8477e+01, 8.3065e+01],\n",
            "        [7.1860e+02, 1.0562e+02, 1.9663e+02, 5.3304e+01],\n",
            "        [9.5418e+02, 3.7431e+02, 1.5054e+02, 7.9339e+01],\n",
            "        [1.1622e+03, 6.5493e+02, 7.7573e+01, 6.2527e+01],\n",
            "        [4.0162e+01, 2.1209e+02, 7.9373e+01, 7.3454e+01],\n",
            "        [1.0532e+03, 1.5579e+00, 1.4747e+02, 3.2318e+00],\n",
            "        [1.1900e+03, 2.8260e+02, 2.0357e+01, 1.4468e+02],\n",
            "        [9.3330e+02, 8.7102e+00, 1.6578e+02, 1.5873e+01]],\n",
            "       grad_fn=<IndexBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Example inputs\n",
        "logits = output.logits  # Shape: [batch_size, num_queries, num_classes]\n",
        "pred_boxes = output.pred_boxes  # Shape: [batch_size, num_queries, 4]\n",
        "image_size = (width, height)  # Replace with your image dimensions\n",
        "\n",
        "# Softmax to get class probabilities\n",
        "probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "# Extract class labels and scores\n",
        "scores, labels = probs.max(dim=-1)\n",
        "\n",
        "# Denormalize boxes to image dimensions\n",
        "boxes = pred_boxes * torch.tensor([image_size[0], image_size[1], image_size[0], image_size[1]])\n",
        "\n",
        "# Apply confidence threshold\n",
        "threshold = 0.95\n",
        "keep = scores > threshold\n",
        "\n",
        "# Filter predictions\n",
        "filtered_boxes = boxes[keep]\n",
        "filtered_scores = scores[keep]\n",
        "filtered_labels = labels[keep]\n",
        "print(filtered_scores)\n",
        "print(filtered_labels)\n",
        "print(filtered_boxes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo02uIX36OtR"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54ple1Zp6OtR"
      },
      "outputs": [],
      "source": [
        "detector = pipeline(task=\"object-detection\")\n",
        "preds = detector(\n",
        "    img_path\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIVIua-o6OtS"
      },
      "outputs": [],
      "source": [
        "preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I6nXW7N6OtS"
      },
      "outputs": [],
      "source": [
        "for i in range(len(preds)):\n",
        "    score = preds[i][\"score\"]\n",
        "    label = preds[i][\"label\"]\n",
        "    box  = preds[i][\"box\"]\n",
        "    print(score , label, box)\n",
        "    x1, y1, x2, y2  = box[\"xmin\"], box[\"ymin\"], box[\"xmax\"], box[\"ymax\"]\n",
        "    print(x1, y1, x2, y2)\n",
        "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    text = f\"{label} ({score})\"\n",
        "    text_y = max(y1 - 10, 10)\n",
        "    cv2.putText(image, text, (x1, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWpH8JHi6OtS"
      },
      "outputs": [],
      "source": [
        "max_index = max(range(len(preds)), key=lambda i: preds[i]['score'])\n",
        "max_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyngvJYL6OtS"
      },
      "outputs": [],
      "source": [
        "\n",
        "image_dir = \"C:\\\\Users\\\\spx016\\\\Downloads\\\\object-detection_bike\\\\\"\n",
        "output_image_dir = \"C:\\\\Users\\\\spx016\\\\Downloads\\\\object-detection_bike\\\\\"\n",
        "for filename in os.listdir(image_dir):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.bmp', '.gif', '.webp')):\n",
        "        # Full path to the image file\n",
        "        filepath = os.path.join(image_dir, filename)\n",
        "\n",
        "        image = Image.open(filepath)\n",
        "        detector = pipeline(task=\"object-detection\")\n",
        "        preds = detector(\n",
        "            filepath\n",
        "        )\n",
        "        img_real = np.array(image)\n",
        "        predictor.set_image(img_real)\n",
        "        img_2 = np.array(image)\n",
        "        try:\n",
        "            # for i in range(len(preds)):\n",
        "            max_index = max(range(len(preds)), key=lambda i: preds[i]['score'])\n",
        "            score = preds[max_index][\"score\"]\n",
        "            label = preds[max_index][\"label\"]\n",
        "            box  = preds[max_index][\"box\"]\n",
        "            print(score , label, box)\n",
        "            x1, y1, x2, y2  = box[\"xmin\"], box[\"ymin\"], box[\"xmax\"], box[\"ymax\"]\n",
        "            input_box = np.array([x1, y1, x2, y2])\n",
        "            input_label = np.array([1])\n",
        "            input_point = np.array([[(x1 + x2) / 2, (y1 + y2) / 2]])\n",
        "\n",
        "\n",
        "            masks, scores, logits = predictor.predict(\n",
        "            point_coords=input_point,\n",
        "            point_labels=input_label,\n",
        "            box = input_box,\n",
        "            multimask_output=False,\n",
        "            hq_token_only=True,\n",
        "            )\n",
        "\n",
        "            mask_uint8 = masks.astype(np.uint8) * 255\n",
        "\n",
        "            mask_color = cv2.merge([mask_uint8, np.zeros_like(mask_uint8), np.zeros_like(mask_uint8)])\n",
        "            mask_color = np.squeeze(mask_color)\n",
        "\n",
        "            # Step 1: Extract the red channel from `mask_color` to create a binary mask\n",
        "            binary_mask = mask_color[..., 0]  # Use only the red channel as `mask_color` is created with red\n",
        "\n",
        "            # Ensure the mask is binary (values: 0 or 255)\n",
        "            binary_mask = (binary_mask > 0).astype(np.uint8) * 255\n",
        "\n",
        "            # Step 2: Resize the mask to match the image size, if needed\n",
        "            if binary_mask.shape[:2] != img_real.shape[:2]:\n",
        "                binary_mask = cv2.resize(binary_mask, (img_real.shape[1], img_real.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            # Step 3: Extract the object using bitwise operation\n",
        "            object_extracted = cv2.bitwise_and(img_real, img_real, mask=binary_mask)\n",
        "\n",
        "            # Step 4: Create a transparent background (optional, if you want PNG with transparency)\n",
        "            object_with_alpha = np.zeros((img_real.shape[0], img_real.shape[1], 4), dtype=np.uint8)\n",
        "            object_with_alpha[..., :3] = object_extracted  # Copy RGB channels\n",
        "            object_with_alpha[..., 3] = binary_mask        # Add alpha channel based on the mask\n",
        "            # Step 5: Display the result\n",
        "            base_name, ext = os.path.splitext(filename)\n",
        "\n",
        "            # Create the output file name with the original name and \"__removedObj\" appended\n",
        "            output_filename = f\"{base_name}__removedObj.png\"\n",
        "            output_path = os.path.join(output_image_dir, output_filename)\n",
        "\n",
        "            cv2.imwrite(output_path, object_with_alpha)\n",
        "            # Save the image\n",
        "\n",
        "            INput_filename = f\"{base_name}____{ext}\"\n",
        "            INput_path = os.path.join(output_image_dir, INput_filename)\n",
        "            image.save(INput_path)\n",
        "            print(f\"Saved image: {output_path}\")\n",
        "            print(f\"Saved image: {INput_path}\")\n",
        "        except:\n",
        "            print(\"  Except Saved image \")\n",
        "            INput_filename = f\"{base_name}__non_SEGMENTATION__{ext}\"\n",
        "            INput_path = os.path.join(output_image_dir, INput_filename)\n",
        "            image.save(INput_path)\n",
        "            print(f\"Except Saved image: {INput_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd4la-5x6OtS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}